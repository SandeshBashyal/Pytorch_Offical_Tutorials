{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9VTutAy6qHuXahDWmRrCn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building Models with PyTorch"
      ],
      "metadata": {
        "id": "T26EHhbtevWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.nn.Module` and `torch.nn.Parameter`"
      ],
      "metadata": {
        "id": "5dtVi0Vce-OW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "\n",
        "One important behavior of `torch.nn.Module` is registering parameters. If a particular Module subclass has learning weights, these weights are expressed as instances of `torch.nn.Parameter`. The `Parameter` class is a subclass of `torch.Tensor`, with the special behavior that when they are assigned as attributes of a `Module`, they are added to the list of that modules parameters. These parameters may be accessed through the `parameters()` method on the `Module` class."
      ],
      "metadata": {
        "id": "tCWmPm6WfNrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TinyModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TinyModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(100, 200)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(200, 10)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "tinymodel = TinyModel()\n",
        "\n",
        "print('The model:')\n",
        "print(tinymodel)\n",
        "\n",
        "print('\\n\\nJust one layer:')\n",
        "print(tinymodel.linear2)\n",
        "\n",
        "print('\\n\\nModel params:')\n",
        "for param in tinymodel.parameters():\n",
        "    print(param)\n",
        "\n",
        "print('\\n\\nLayer params:')\n",
        "for param in tinymodel.linear2.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuFEiMs0fhyD",
        "outputId": "5b824948-c0d5-4840-82bd-52005df69e7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "TinyModel(\n",
            "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "\n",
            "Just one layer:\n",
            "Linear(in_features=200, out_features=10, bias=True)\n",
            "\n",
            "\n",
            "Model params:\n",
            "Parameter containing:\n",
            "tensor([[-0.0678, -0.0083,  0.0389,  ...,  0.0846, -0.0746,  0.0811],\n",
            "        [-0.0356, -0.0681,  0.0407,  ..., -0.0334,  0.0926, -0.0103],\n",
            "        [-0.0768,  0.0274, -0.0580,  ...,  0.0773, -0.0267, -0.0276],\n",
            "        ...,\n",
            "        [-0.0742,  0.0702, -0.0173,  ...,  0.0899,  0.0311, -0.0975],\n",
            "        [ 0.0210, -0.0501,  0.0672,  ..., -0.0244, -0.0752, -0.0604],\n",
            "        [-0.0501, -0.0739, -0.0244,  ..., -0.0244,  0.0633, -0.0640]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0908,  0.0186, -0.0268, -0.0434, -0.0570, -0.0222, -0.0604,  0.0200,\n",
            "        -0.0494, -0.0108,  0.0860,  0.0659, -0.0044, -0.0891, -0.0466, -0.0179,\n",
            "         0.0430,  0.0358, -0.0626, -0.0990, -0.0264, -0.0523, -0.0737, -0.0636,\n",
            "         0.0451, -0.0022, -0.0100,  0.0407, -0.0100,  0.0976, -0.0827, -0.0926,\n",
            "        -0.0836, -0.0206, -0.0681,  0.0263, -0.0263, -0.0255, -0.0569,  0.0569,\n",
            "        -0.0730, -0.0484, -0.0807, -0.0075, -0.0978, -0.0630,  0.0797,  0.0573,\n",
            "        -0.0649, -0.0988, -0.0939,  0.0449,  0.0330, -0.0707,  0.0989,  0.0501,\n",
            "         0.0461, -0.0071,  0.0821, -0.0606, -0.0969, -0.0717, -0.0080, -0.0319,\n",
            "         0.0823,  0.0838, -0.0829,  0.0009,  0.0598, -0.0764, -0.0340, -0.0149,\n",
            "         0.0072,  0.0121, -0.0954, -0.0961,  0.0862,  0.0114,  0.0793, -0.0361,\n",
            "        -0.0072, -0.0627, -0.0690, -0.0917,  0.0320, -0.0401, -0.0219,  0.0696,\n",
            "        -0.0797, -0.0466, -0.0469,  0.0083,  0.0097, -0.0222, -0.0789, -0.0893,\n",
            "         0.0290,  0.0071,  0.0926, -0.0227, -0.0977,  0.0165,  0.0334,  0.0561,\n",
            "         0.0869, -0.0367, -0.0334,  0.0956, -0.0607,  0.0660,  0.0496,  0.0541,\n",
            "         0.0689, -0.0142,  0.0274,  0.0707,  0.0852,  0.0190, -0.0239,  0.0158,\n",
            "         0.0145, -0.0942,  0.0959,  0.0373, -0.0174, -0.0406, -0.0845, -0.0423,\n",
            "         0.0070, -0.0366,  0.0659,  0.0525,  0.0330,  0.0200, -0.0718,  0.0042,\n",
            "        -0.0626,  0.0845,  0.0110,  0.0715,  0.0412, -0.0718,  0.0250, -0.0842,\n",
            "         0.0016, -0.0227, -0.0510,  0.0847,  0.0454,  0.0596, -0.0804, -0.0002,\n",
            "         0.0706,  0.0566, -0.0249,  0.0334, -0.0930,  0.0856,  0.0572, -0.0555,\n",
            "         0.0035, -0.0221,  0.0879,  0.0306,  0.0327, -0.0251, -0.0522,  0.0071,\n",
            "        -0.0721, -0.0282,  0.0453,  0.0205,  0.0841,  0.0781, -0.0358, -0.0532,\n",
            "        -0.0803, -0.0104, -0.0857,  0.0406,  0.0544,  0.0999,  0.0522, -0.0789,\n",
            "        -0.0457,  0.0201,  0.0322, -0.0849,  0.0491,  0.0763, -0.0485, -0.0815,\n",
            "        -0.0931,  0.0828, -0.0488,  0.0792,  0.0010, -0.0430, -0.0470,  0.0630],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0008, -0.0297,  0.0524,  ...,  0.0631, -0.0546, -0.0056],\n",
            "        [-0.0298, -0.0340, -0.0570,  ..., -0.0130, -0.0048, -0.0031],\n",
            "        [-0.0134, -0.0330,  0.0060,  ...,  0.0519, -0.0208, -0.0672],\n",
            "        ...,\n",
            "        [-0.0614,  0.0197, -0.0036,  ...,  0.0680,  0.0286, -0.0010],\n",
            "        [-0.0310, -0.0088, -0.0216,  ..., -0.0316, -0.0540, -0.0404],\n",
            "        [ 0.0030,  0.0141, -0.0275,  ...,  0.0131,  0.0276,  0.0487]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0637, -0.0481, -0.0223,  0.0032, -0.0074, -0.0062, -0.0545,  0.0022,\n",
            "         0.0504,  0.0173], requires_grad=True)\n",
            "\n",
            "\n",
            "Layer params:\n",
            "Parameter containing:\n",
            "tensor([[-0.0008, -0.0297,  0.0524,  ...,  0.0631, -0.0546, -0.0056],\n",
            "        [-0.0298, -0.0340, -0.0570,  ..., -0.0130, -0.0048, -0.0031],\n",
            "        [-0.0134, -0.0330,  0.0060,  ...,  0.0519, -0.0208, -0.0672],\n",
            "        ...,\n",
            "        [-0.0614,  0.0197, -0.0036,  ...,  0.0680,  0.0286, -0.0010],\n",
            "        [-0.0310, -0.0088, -0.0216,  ..., -0.0316, -0.0540, -0.0404],\n",
            "        [ 0.0030,  0.0141, -0.0275,  ...,  0.0131,  0.0276,  0.0487]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0637, -0.0481, -0.0223,  0.0032, -0.0074, -0.0062, -0.0545,  0.0022,\n",
            "         0.0504,  0.0173], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Layer Types"
      ],
      "metadata": {
        "id": "fcdgmmE9gNiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Layers"
      ],
      "metadata": {
        "id": "zpi8JG8pgbp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin = torch.nn.Linear(3, 2)     # 3 inputs, 2 outputs\n",
        "x = torch.rand(1, 3)\n",
        "print('Input:')\n",
        "print(x)\n",
        "\n",
        "print('\\n\\nWeight and Bias parameters:')\n",
        "for param in lin.parameters():\n",
        "    print(param)\n",
        "\n",
        "y = lin(x)\n",
        "print('\\n\\nOutput:')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBFYX42Ggdw1",
        "outputId": "f4d04b0c-d5cf-4a14-91ae-7f894e69b834"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            "tensor([[0.1672, 0.9918, 0.5229]])\n",
            "\n",
            "\n",
            "Weight and Bias parameters:\n",
            "Parameter containing:\n",
            "tensor([[ 0.3893, -0.5746, -0.2660],\n",
            "        [-0.5176, -0.0223,  0.3729]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.4292, -0.5554], requires_grad=True)\n",
            "\n",
            "\n",
            "Output:\n",
            "tensor([[-0.2146, -0.4691]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you do the matrix multiplication of `x` by the linear layer’s weights, and add the biases, you’ll find that you get the output vector `y`.\n",
        "\n",
        "One other important feature to note: When we checked the weights of our layer with `lin.weight`, it reported itself as a `Parameter` (which is a subclass of `Tensor`), and let us know that it’s tracking gradients with autograd. This is a default behavior for `Parameter` that differs from `Tensor`."
      ],
      "metadata": {
        "id": "agTuBREygiKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolutional Layers"
      ],
      "metadata": {
        "id": "MnwfoaZHlOKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional layers are built to handle data with a high degree of spatial correlation. They are very commonly used in computer vision, where they detect close groupings of features which the compose into higher-level features. They pop up in other contexts too - for example, in NLP applications, where a word’s immediate context (that is, the other words nearby in the sequence) can affect the meaning of a sentence."
      ],
      "metadata": {
        "id": "H0ZmZnXhlRlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.functional as F\n",
        "\n",
        "\n",
        "class LeNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = torch.nn.Conv2d(1, 6, 5) #(1, 6, (5, 5))\n",
        "        # The first argument to a convolutional layer’s constructor is the number of input channels\n",
        "        # This is the second argument to the constructor is the number of output features.\n",
        "        # The third argument is the window or kernel size.\n",
        "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = torch.nn.Linear(120, 84)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "AWfAcrCBlZM5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down what's happening in the convolutional layer:\n",
        "\n",
        "1. The first argument to a convolutional layer’s constructor is the number of input channels\n",
        "\n",
        "2. This is the second argument to the constructor is the number of output features.\n",
        "\n",
        "3. The third argument is the window or kernel size. eg: `(3, 5)` to get a 3x5 convolution kernel."
      ],
      "metadata": {
        "id": "eDGqFLuDll1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of a convolutional layer is an activation map - a spatial representation of the presence of features in the input tensor. conv1 will give us an output tensor of 6x28x28; 6 is the number of features, and 28 is the height and width of our map. (The 28 comes from the fact that when scanning a 5-pixel window over a 32-pixel row, there are only 28 valid positions.)"
      ],
      "metadata": {
        "id": "0wOVxgCjm10j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then pass the output of the convolution through a ReLU activation function (more on activation functions later), then through a max pooling layer. The max pooling layer takes features near each other in the activation map and groups them together. It does this by reducing the tensor, merging every 2x2 group of cells in the output into a single cell, and assigning that cell the maximum value of the 4 cells that went into it. This gives us a lower-resolution version of the activation map, with dimensions 6x14x14."
      ],
      "metadata": {
        "id": "Oynsw3l0m6GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next convolutional layer, conv2, expects 6 input channels (corresponding to the 6 features sought by the first layer), has 16 output channels, and a 3x3 kernel. It puts out a 16x12x12 activation map, which is again reduced by a max pooling layer to 16x6x6. Prior to passing this output to the linear layers, it is reshaped to a 16 * 6 * 6 = 576-element vector for consumption by the next layer.\n",
        "\n",
        "There are convolutional layers for addressing 1D, 2D, and 3D tensors. There are also many more optional arguments for a conv layer constructor, including stride length(e.g., only scanning every second or every third position) in the input, padding (so you can scan out to the edges of the input), and more. See the [documentation](https://pytorch.org/docs/stable/nn.html#convolution-layers) for more information."
      ],
      "metadata": {
        "id": "XZRoVqMunVTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Layers"
      ],
      "metadata": {
        "id": "JRyXAtpznq5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far."
      ],
      "metadata": {
        "id": "iiSzwS_snstY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM (long short-term memory)\n",
        "# GRU (gated recurrent unit)\n",
        "class LSTMTagger(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "6vKcKelLn2Vk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/nlp/\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "\n",
        "The constructor has four arguments:\n",
        "\n",
        "1. `vocab_size` is the number of words in the input vocabulary. Each word is a one-hot vector (or unit vector) in a `vocab_size`-dimensional space.\n",
        "\n",
        "2. `tagset_size` is the number of tags in the output set.\n",
        "\n",
        "3. `embedding_dim` is the size of the embedding space for the vocabulary. An embedding maps a vocabulary onto a low-dimensional space, where words with similar meanings are close together in the space.\n",
        "\n",
        "4. `hidden_dim` is the size of the LSTM’s memory."
      ],
      "metadata": {
        "id": "E-E1um8DoLiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers"
      ],
      "metadata": {
        "id": "UrojhYLbo2fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/docs/stable/nn.html#transformer-layers\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
      ],
      "metadata": {
        "id": "az4GexlFqAns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Layers and Functions"
      ],
      "metadata": {
        "id": "dmD_pcRNqQGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html#other-layers-and-functions"
      ],
      "metadata": {
        "id": "m8BWVOeTsP1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulation Layers"
      ],
      "metadata": {
        "id": "JTSfECgMqTvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max pooling (and its twin, min pooling) reduce a tensor by combining cells, and assigning the maximum value of the input cells to the output cell (we saw this)."
      ],
      "metadata": {
        "id": "_xKvdKxSqW6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 6, 6)\n",
        "print(my_tensor)\n",
        "\n",
        "maxpool_layer = torch.nn.MaxPool2d(3)       # 3 * 3 max value: each quadrant of 6 * 6 input\n",
        "print(maxpool_layer(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrgbSHrZqeYb",
        "outputId": "e2d32b5d-b093-4963-ae19-07df1a549c8a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2374, 0.6107, 0.7623, 0.4106, 0.6409, 0.9780],\n",
            "         [0.5889, 0.3431, 0.4157, 0.0494, 0.6288, 0.7908],\n",
            "         [0.8304, 0.3715, 0.3963, 0.4810, 0.1997, 0.9967],\n",
            "         [0.5372, 0.2004, 0.9509, 0.9904, 0.4673, 0.6919],\n",
            "         [0.7814, 0.0688, 0.2617, 0.3582, 0.4661, 0.0269],\n",
            "         [0.2980, 0.1115, 0.4167, 0.2535, 0.3754, 0.9538]]])\n",
            "tensor([[[0.8304, 0.9967],\n",
            "         [0.9509, 0.9904]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization layers** re-center and normalize the output of one layer before feeding it to another. Centering the and scaling the intermediate tensors has a number of beneficial effects, such as letting you use higher learning rates without exploding/vanishing gradients."
      ],
      "metadata": {
        "id": "fkQWdmmTqfr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
        "print(my_tensor)\n",
        "\n",
        "print(my_tensor.mean())\n",
        "\n",
        "norm_layer = torch.nn.BatchNorm1d(4)\n",
        "normed_tensor = norm_layer(my_tensor)\n",
        "print(normed_tensor)\n",
        "\n",
        "print(normed_tensor.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO8OKVkYrNTE",
        "outputId": "2686899c-b5e8-43cb-8e07-bd0ee1d4b29b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[19.1950, 22.5907, 10.8352,  8.4007],\n",
            "         [12.7303,  5.9058,  7.0304, 14.9840],\n",
            "         [14.0016,  9.8467, 19.7862, 12.3650],\n",
            "         [14.6087, 22.4253, 11.5003, 11.9954]]])\n",
            "tensor(13.6376)\n",
            "tensor([[[ 6.7600e-01,  1.2587e+00, -7.5847e-01, -1.1762e+00],\n",
            "         [ 6.7565e-01, -1.1201e+00, -8.2420e-01,  1.2687e+00],\n",
            "         [ 4.7868e-04, -1.1367e+00,  1.5836e+00, -4.4744e-01],\n",
            "         [-1.1975e-01,  1.6677e+00, -8.3058e-01, -7.1736e-01]]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n",
            "tensor(-5.2154e-08, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout layers** are a tool for encouraging sparse representations in your model - that is, pushing it to do inference with less data.\n",
        "\n",
        "Dropout layers work by randomly setting parts of the input tensor during training - dropout layers are always turned off for inference. This forces the model to learn against this masked or reduced dataset.\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html"
      ],
      "metadata": {
        "id": "je6Ueop2rN87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4)\n",
        "\n",
        "dropout = torch.nn.Dropout(p=0.4)\n",
        "print(dropout(my_tensor))\n",
        "print(dropout(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC_L3x_msYgI",
        "outputId": "4eb4cbb3-a94a-4c91-9d5f-164faa558abd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.4551, 0.0000, 0.0000, 1.4674],\n",
            "         [0.0000, 1.1179, 0.6502, 0.0000],\n",
            "         [0.0000, 0.0000, 1.3803, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.7054]]])\n",
            "tensor([[[1.4551, 0.3403, 0.3280, 0.0000],\n",
            "         [0.4372, 0.0000, 0.6502, 0.7847],\n",
            "         [0.9113, 0.5016, 1.3803, 0.0000],\n",
            "         [0.8670, 0.0000, 0.5093, 0.7054]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activations Functions"
      ],
      "metadata": {
        "id": "yZVDFIyPscmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.nn.Module` has objects encapsulating all of the major activation functions including `ReLU` and its many `variants`, `Tanh`, `Hardtanh`, `sigmoid`, and more. It also includes other functions, such as `Softmax`, that are most useful at the output stage of a model."
      ],
      "metadata": {
        "id": "dHZiDDuQs-En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Functions"
      ],
      "metadata": {
        "id": "59Kd28eTtqb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss functions** tell us how far a model’s prediction is from the correct answer. PyTorch contains a variety of loss functions, including common `MSE` (`mean squared error` = L2 norm), `Cross Entropy Loss` and `Negative Likelihood Loss` (useful for classifiers), and others."
      ],
      "metadata": {
        "id": "APllK0Nstu0n"
      }
    }
  ]
}