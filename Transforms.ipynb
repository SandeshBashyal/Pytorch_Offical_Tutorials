{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2sidFadBN9sezGS7Zer0/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transforms"
      ],
      "metadata": {
        "id": "HbDQxBQc_vZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data does not always come in its final processed form that is required for training machine learning algorithms. We use transforms to perform some manipulation of the data and make it suitable for training.\n",
        "\n",
        "Parameters :\n",
        "\n",
        "-transform\n",
        "\n",
        "-target_transform\n",
        ""
      ],
      "metadata": {
        "id": "EXisqcRnAHL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        "    target_transform = Lambda(lambda y: torch.zeros(10, dtype = torch.float).scatter_(0, torch.tensor(y), value = 1))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guFxF0r-AIbJ",
        "outputId": "cec95468-14cc-4371-b6a1-cb5daf1f7cac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:14<00:00, 1785392.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 57753.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:09<00:00, 479838.39it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 18597999.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ToTensor()"
      ],
      "metadata": {
        "id": "-82YiBr1BqV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToTensor converts a PIL (Python Imaging Library) image or NumPy ndarray into a FloatTensor and scales the image’s pixel intensity values in the range [0., 1.]"
      ],
      "metadata": {
        "id": "0RYurwFEBtCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lambda Transforms"
      ],
      "metadata": {
        "id": "1LqKbR48Byck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`target_transform = Lambda(lambda y: torch.zeros(\n",
        "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))`"
      ],
      "metadata": {
        "id": "uaxStx8LDdTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lambda transforms apply any user-defined lambda function. Here, we defined a function to turn the integer into a one-hot encoded tensor. It first created a zero tensor of size 10 (the number of labels in our dataset) and called scatter_ which assigned a value=1 on the index as given by the label y."
      ],
      "metadata": {
        "id": "YJb4Lra5DLgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/vision/stable/transforms.html"
      ],
      "metadata": {
        "id": "QsKPz045Dlh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lambda function"
      ],
      "metadata": {
        "id": "4EchZpm7EvmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A lambda function is small anonymous function that can take any number of arguments, but can have only one expression.\n",
        "\n",
        "The expression `lambda parameters: expression` yields a function object. The unnamed object behaves like a function object defined with:"
      ],
      "metadata": {
        "id": "Owyf7FiAE0GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples:\n",
        "x = lambda a, b, c : a + b + c\n",
        "print(x(5, 6, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coR0RQbyGXLj",
        "outputId": "93c2cf71-0b4d-4fba-8467-89d7c91bd0a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    }
  ]
}